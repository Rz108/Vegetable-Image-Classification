{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Part A: Convolutional Neural Network__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1\"></a>\n",
    "## <font color='#71a1e3'> __Previously__</font>\n",
    "<hr style=\"height:1.5px;border-width:0;background-color: #4c8c77\">\n",
    "\n",
    "1. Model Improvement part 1 was done\n",
    "2. 31 x 31 Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"3\"></a>\n",
    "## <font color='#71a1e3'>__Import Libraries__</font>\n",
    "<hr style=\"height:1.5px;border-width:0;background-color: #4c8c77\">\n",
    "\n",
    "Here is to import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip 1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.8/dist-packages (0.21.0)\n",
      "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.8/dist-packages (1.4.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (2.0.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.5.2)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (0.13.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.3.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.66.1)\n",
      "Requirement already satisfied: efficientnet in /usr/local/lib/python3.8/dist-packages (1.1.1)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.31.0)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.9.0)\n",
      "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (9.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.8/dist-packages (from efficientnet) (1.0.8)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from efficientnet) (0.21.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->keras-tuner) (1.25.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->keras-tuner) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->keras-tuner) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (3.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.14.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.6.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (2023.7.10)\n",
      "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (3.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (0.3)\n",
      "Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (2.33.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow_addons keras-tuner pandas matplotlib seaborn scikit-learn tqdm efficientnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score, confusion_matrix, cohen_kappa_score, matthews_corrcoef\n",
    "from sklearn.metrics import classification_report,accuracy_score, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import os, time, math, datetime, warnings, pytz, glob\n",
    "from IPython.display import display\n",
    "from functools import reduce\n",
    "import absl.logging\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from efficientnet.tfkeras import EfficientNetB3\n",
    "\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from tensorflow import expand_dims\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.image import random_flip_left_right, random_crop, resize_with_crop_or_pad\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import (Dense, Input, InputLayer, Normalization, Flatten,BatchNormalization,\n",
    "    Dropout,Conv2D, GlobalAveragePooling2D, MaxPooling2D, ReLU, Layer,Activation, Multiply, AveragePooling2D,\n",
    "    Add, RandomRotation,Resizing, Rescaling, Reshape, Concatenate, concatenate, Lambda,LeakyReLU, ZeroPadding2D)\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, TerminateOnNaN, TensorBoard, CSVLogger, Callback\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam, Adagrad, Adamax\n",
    "from tensorflow.keras.regularizers import l2, L2\n",
    "from tensorflow.keras.optimizers.schedules import *\n",
    "from tensorflow.keras.metrics import FalseNegatives, categorical_crossentropy, sparse_categorical_crossentropy\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.image import *\n",
    "from tensorflow_addons.optimizers import SWA\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from kerastuner.tuners import Hyperband\n",
    "from kerastuner import RandomSearch\n",
    "from kerastuner import HyperModel\n",
    "# Setting a seaborn style\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the seed of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 32\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"3\"></a>\n",
    "## <font color='#71a1e3'>__Check for GPU__</font>\n",
    "<hr style=\"height:1.5px;border-width:0;background-color: #4c8c77\">\n",
    "\n",
    "Here is check the available GPUs and set the memory growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 26 08:23:20 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  | 00000000:03:00.0 Off |                  Off |\n",
      "|  0%   43C    P2              54W / 450W |    575MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"4\"></a>\n",
    "## <font color='#71a1e3'>__Import dataset__</font>\n",
    "<hr style=\"height:1.5px;border-width:0;background-color: #4c8c77\">\n",
    "\n",
    "Here is to import the dataset and proceed to do analysis on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31 x 31 Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9028 files belonging to 15 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 31, 31, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_small = tf.keras.utils.image_dataset_from_directory('Dataset for CA1 part A/train'  ,\n",
    "                                                   color_mode='rgb',\n",
    "                                                   image_size=(31,31))\n",
    "data_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 283/283 [00:01<00:00, 204.25it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_small = []\n",
    "y_train_small = []\n",
    "\n",
    "for images, labels in tqdm(data_small):\n",
    "    images = tf.image.rgb_to_grayscale(images)\n",
    "    X_train_small.append(images)\n",
    "    y_train_small.append(labels)\n",
    "\n",
    "X_train_small = np.concatenate(X_train_small, axis=0)\n",
    "X_train_small = np.squeeze(X_train_small, axis=-1)\n",
    "y_train_small = np.concatenate(y_train_small, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 files belonging to 15 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 31, 31, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_small = tf.keras.utils.image_dataset_from_directory('Dataset for CA1 part A/validation'  ,\n",
    "                                                   color_mode='rgb',\n",
    "                                                   image_size=(31,31))\n",
    "val_data_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:00<00:00, 394.27it/s]\n"
     ]
    }
   ],
   "source": [
    "X_val_small = []\n",
    "y_val_small = []\n",
    "\n",
    "for images, labels in tqdm(val_data_small):\n",
    "    images = tf.image.rgb_to_grayscale(images)\n",
    "    X_val_small.append(images)\n",
    "    y_val_small.append(labels)\n",
    "\n",
    "X_val_small = np.concatenate(X_val_small, axis=0)\n",
    "X_val_small = np.squeeze(X_val_small, axis=-1)\n",
    "y_val_small = np.concatenate(y_val_small, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 files belonging to 15 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 31, 31, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_small = tf.keras.utils.image_dataset_from_directory('Dataset for CA1 part A/test'  ,\n",
    "                                                   color_mode='rgb',\n",
    "                                                   image_size=(31,31))\n",
    "test_data_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:00<00:00, 396.95it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_small = []\n",
    "y_test_small = []\n",
    "\n",
    "for images, labels in tqdm(test_data_small):\n",
    "    images = tf.image.rgb_to_grayscale(images)\n",
    "    X_test_small.append(images)\n",
    "    y_test_small.append(labels)\n",
    "\n",
    "X_test_small = np.concatenate(X_test_small, axis=0)\n",
    "X_test_small = np.squeeze(X_test_small, axis=-1)\n",
    "y_test_small = np.concatenate(y_test_small, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_small = to_categorical(y_train_small)\n",
    "y_val_small = to_categorical(y_val_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Bean', 1: 'Bitter_Gourd', 2: 'Bottle_Gourd', 3: 'Brinjal', 4: 'Broccoli', 5: 'Cabbage', 6: 'Capsicum', 7: 'Carrot', 8: 'Cauliflower', 9: 'Cucumber', 10: 'Papaya', 11: 'Potato', 12: 'Pumpkin', 13: 'Radish', 14: 'Tomato'}\n"
     ]
    }
   ],
   "source": [
    "labels_dict = os.listdir('Dataset for CA1 part A/train')\n",
    "labels_dict = {idx: label for idx, label in enumerate(labels_dict)}\n",
    "print(labels_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"4\"></a>\n",
    "## <font color='#71a1e3'>__Required Functions__</font>\n",
    "<hr style=\"height:1.5px;border-width:0;background-color: #4c8c77\">\n",
    "\n",
    "Here is to set the required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(image, label):\n",
    "  image = tf.expand_dims(image, -1)\n",
    "  return image, label\n",
    "\n",
    "def sample_beta_distribution(size, concentration_0=300, concentration_1=0.1):\n",
    "  gamma_1_sample = tf.random.gamma(shape=[size], alpha=concentration_1)\n",
    "  gamma_2_sample = tf.random.gamma(shape=[size], alpha=concentration_0)\n",
    "  return gamma_1_sample / (gamma_1_sample + gamma_2_sample)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def get_box(lambda_value):\n",
    "  cut_rat = tf.math.sqrt(1.0 - lambda_value)\n",
    "  image_wh = (31,31,1)[0]\n",
    "  cut_wh = image_wh * cut_rat  # rw\n",
    "  cut_wh = tf.cast(cut_wh, tf.int32)\n",
    "\n",
    "  cut_x = tf.random.uniform((1,), minval=0, maxval=image_wh, dtype=tf.int32)  # rx\n",
    "  cut_y = tf.random.uniform((1,), minval=0, maxval=image_wh, dtype=tf.int32)  # ry\n",
    "\n",
    "  boundaryx1 = tf.clip_by_value(cut_x[0] - cut_wh // 2, 0, image_wh)\n",
    "  boundaryy1 = tf.clip_by_value(cut_y[0] - cut_wh // 2, 0, image_wh)\n",
    "  bbx2 = tf.clip_by_value(cut_x[0] + cut_wh // 2, 0, image_wh)\n",
    "  bby2 = tf.clip_by_value(cut_y[0] + cut_wh // 2, 0, image_wh)\n",
    "\n",
    "  target_h = bby2 - boundaryy1\n",
    "  if target_h == 0:\n",
    "      target_h += 1\n",
    "\n",
    "  target_w = bbx2 - boundaryx1\n",
    "  if target_w == 0:\n",
    "      target_w += 1\n",
    "\n",
    "  return boundaryx1, boundaryy1, target_h, target_w\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def cutmix(train_ds_one, train_ds_two):\n",
    "  (image1, label1), (image2, label2) = train_ds_one, train_ds_two\n",
    "  image_size = (31,31,1)[0]\n",
    "  alpha = [1]\n",
    "  beta = [1]\n",
    "  lambda_value = sample_beta_distribution(1, alpha, beta)\n",
    "  lambda_value = lambda_value[0][0]\n",
    "  boundaryx1, boundaryy1, target_h, target_w = get_box(lambda_value)\n",
    "  crop2 = tf.image.crop_to_bounding_box(\n",
    "      image2, boundaryy1, boundaryx1, target_h, target_w\n",
    "  )\n",
    "  image2 = tf.image.pad_to_bounding_box(\n",
    "      crop2, boundaryy1, boundaryx1, image_size, image_size\n",
    "  )\n",
    "  crop1 = tf.image.crop_to_bounding_box(\n",
    "      image1, boundaryy1, boundaryx1, target_h, target_w\n",
    "  )\n",
    "  img1 = tf.image.pad_to_bounding_box(\n",
    "      crop1, boundaryy1, boundaryx1, image_size, image_size\n",
    "  )\n",
    "\n",
    "  image1 = image1 - img1\n",
    "  image = image1 + image2\n",
    "  lambda_value = 1 - (target_w * target_h) / (image_size * image_size)\n",
    "  lambda_value = tf.cast(lambda_value, tf.float32)\n",
    "  label = lambda_value * label1 + (1 - lambda_value) * label2\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 31, 31, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_one = tf.data.Dataset.from_tensor_slices((X_train_small, y_train_small)).shuffle(2048).map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds_two = tf.data.Dataset.from_tensor_slices((X_train_small, y_train_small)).shuffle(2048).map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds_cutmix = tf.data.Dataset.from_tensor_slices((X_val_small, y_val_small))\n",
    "val_ds_cutmix = val_ds_cutmix.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE).batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds_cutmix = tf.data.Dataset.zip((train_ds_one, train_ds_two))\n",
    "train_ds_cutmix = (\n",
    "    train_ds_cutmix.shuffle(1024)\n",
    "    .map(cutmix, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(128)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "train_ds_cutmix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1\"></a>\n",
    "## <font color='#71a1e3'> __Hyperparameter Tuning__</font>\n",
    "<hr style=\"height:1.5px;border-width:0;background-color: #4c8c77\">\n",
    "\n",
    "Here we will do the hyperparamter tuning on the CNN model created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model 1\n",
    "\n",
    "- Hypertune the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9028, 15)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 58s]\n",
      "val_accuracy: 0.9300000071525574\n",
      "\n",
      "Best val_accuracy So Far: 0.9300000071525574\n",
      "Total elapsed time: 00h 21m 19s\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    K.clear_session() \n",
    "    \n",
    "    model = Sequential(name=hp.Choice('model_name', ['CNN_Baseline_LR']))\n",
    "\n",
    "    # First Convolutional Block\n",
    "    model.add(Conv2D(hp.Int('conv_1_filters', min_value=32, max_value=128, step=32),\n",
    "                     (hp.Choice('conv_1_kernel', [3, 5])),\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     input_shape=(31, 31, 1),\n",
    "                     kernel_regularizer=l2(hp.Float('conv_1_l2', min_value=1e-4, max_value=1e-2, sampling='log'))))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    model.add(Conv2D(hp.Int('conv_2_filters', min_value=64, max_value=256, step=64),\n",
    "                     (hp.Choice('conv_2_kernel', [3, 5])),\n",
    "                     padding='same',\n",
    "                     activation='relu',\n",
    "                     kernel_regularizer=l2(hp.Float('conv_2_l2', min_value=1e-4, max_value=1e-2, sampling='log'))))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(hp.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Dense Block\n",
    "    model.add(Dense(hp.Int('dense_1_units', min_value=128, max_value=1024, step=128),\n",
    "                    activation='relu',\n",
    "                    kernel_regularizer=l2(hp.Float('dense_1_l2', min_value=1e-4, max_value=1e-2, sampling='log'))))\n",
    "    model.add(Dropout(hp.Float('dropout_3', min_value=0.1, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(15, activation='softmax'))\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Initialize the Random Search tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='randomsearch1',\n",
    "    project_name='randomsearch_cnn'\n",
    ")\n",
    "\n",
    "tuner.search(train_ds_cutmix, epochs=80, validation_data=val_ds_cutmix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model 2 (Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn2_model(hp):\n",
    "    model = Sequential(name='CNN2_Baseline')\n",
    "\n",
    "    # First Convolutional Layer with optional regularizer\n",
    "    model.add(Conv2D(\n",
    "        filters=hp.Int('filters_1', min_value=32, max_value=128, step=32),\n",
    "        kernel_size=(3, 3),\n",
    "        padding='same',\n",
    "        input_shape=(31,31,1),\n",
    "        kernel_regularizer=None if hp.Choice('use_l2_reg_1', [True, False]) == False else l2(hp.Float('l2_reg_1', min_value=1e-5, max_value=1e-2, sampling='LOG'))\n",
    "    ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    # Additional Convolutional Layers with optional regularizers\n",
    "    for i in range(hp.Int('num_conv_layers', 2, 5)):\n",
    "        model.add(Conv2D(\n",
    "            filters=hp.Int(f'filters_{i+2}', min_value=32, max_value=128, step=32),\n",
    "            kernel_size=(3, 3),\n",
    "            padding='same',\n",
    "            kernel_regularizer=None if hp.Choice(f'use_l2_reg_{i+2}', [True, False]) == False else l2(hp.Float(f'l2_reg_{i+2}', min_value=1e-5, max_value=1e-2, sampling='LOG'))\n",
    "        ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units', min_value=64, max_value=256, step=32),\n",
    "        activation='relu',\n",
    "        kernel_regularizer=None if hp.Choice('use_l2_reg_dense', [True, False]) == False else l2(hp.Float('l2_reg_dense', min_value=1e-5, max_value=1e-2, sampling='LOG'))\n",
    "    ))\n",
    "    model.add(Dropout(hp.Float('dropout', min_value=0, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(15, activation='softmax'))\n",
    "    optimizer_name = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
    "    \n",
    "    # Setting optimizer parameters\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam(\n",
    "            learning_rate=hp.Float('adam_lr', min_value=1e-4, max_value=1e-2, sampling='LOG'))\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = SGD(\n",
    "            learning_rate=hp.Float('sgd_lr', min_value=1e-4, max_value=1e-2, sampling='LOG'),\n",
    "            momentum=hp.Float('sgd_momentum', min_value=0.0, max_value=0.9, step=0.1))\n",
    "    elif optimizer_name == 'rmsprop':\n",
    "        optimizer = RMSprop(\n",
    "            learning_rate=hp.Float('rmsprop_lr', min_value=1e-4, max_value=1e-2, sampling='LOG'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 01m 22s]\n",
      "val_accuracy: 0.2863333225250244\n",
      "\n",
      "Best val_accuracy So Far: 0.9473333358764648\n",
      "Total elapsed time: 00h 16m 37s\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Search tuner\n",
    "tuner = RandomSearch(\n",
    "    build_cnn2_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=15,\n",
    "    executions_per_trial=1,\n",
    "    directory='randomsearch2.5',\n",
    "    project_name='randomsearch_cnn'\n",
    ")\n",
    "\n",
    "\n",
    "tuner.search(train_ds_cutmix, epochs=80, validation_data=val_ds_cutmix, callbacks = [EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True), ReduceLROnPlateau(patience=5)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN2_Baseline\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 31, 31, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 31, 31, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 31, 31, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 31, 31, 96)        27744     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 31, 31, 96)       384       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              (None, 31, 31, 96)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 31, 31, 64)        55360     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 31, 31, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_7 (ReLU)              (None, 31, 31, 64)        0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 31, 31, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 31, 31, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_8 (ReLU)              (None, 31, 31, 128)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 31, 31, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 31, 31, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_9 (ReLU)              (None, 31, 31, 128)       0         \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 128)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 15)                3855      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 343,535\n",
      "Trainable params: 342,639\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "70/70 [==============================] - 3s 22ms/step - loss: 2.6013 - accuracy: 0.2736 - val_loss: 24.0281 - val_accuracy: 0.0667 - lr: 0.0037\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 2.1662 - accuracy: 0.3858 - val_loss: 7.0021 - val_accuracy: 0.0850 - lr: 0.0037\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 2.0328 - accuracy: 0.4474 - val_loss: 4.9553 - val_accuracy: 0.1380 - lr: 0.0037\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.9619 - accuracy: 0.4766 - val_loss: 3.4952 - val_accuracy: 0.2380 - lr: 0.0037\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.8600 - accuracy: 0.5392 - val_loss: 5.5750 - val_accuracy: 0.1733 - lr: 0.0037\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.7727 - accuracy: 0.5735 - val_loss: 3.3633 - val_accuracy: 0.2110 - lr: 0.0037\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.7228 - accuracy: 0.5949 - val_loss: 4.0634 - val_accuracy: 0.1783 - lr: 0.0037\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.6471 - accuracy: 0.6320 - val_loss: 3.7453 - val_accuracy: 0.2303 - lr: 0.0037\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.6276 - accuracy: 0.6385 - val_loss: 2.4922 - val_accuracy: 0.3700 - lr: 0.0037\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.5909 - accuracy: 0.6549 - val_loss: 5.2222 - val_accuracy: 0.1413 - lr: 0.0037\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.5624 - accuracy: 0.6742 - val_loss: 2.0528 - val_accuracy: 0.4303 - lr: 0.0037\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.5178 - accuracy: 0.6899 - val_loss: 3.5498 - val_accuracy: 0.2973 - lr: 0.0037\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.4932 - accuracy: 0.7056 - val_loss: 2.6910 - val_accuracy: 0.3357 - lr: 0.0037\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.4674 - accuracy: 0.7158 - val_loss: 2.1745 - val_accuracy: 0.4693 - lr: 0.0037\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.4474 - accuracy: 0.7210 - val_loss: 1.2854 - val_accuracy: 0.6517 - lr: 0.0037\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.4193 - accuracy: 0.7350 - val_loss: 3.2798 - val_accuracy: 0.3103 - lr: 0.0037\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.4093 - accuracy: 0.7406 - val_loss: 1.8092 - val_accuracy: 0.5383 - lr: 0.0037\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.4022 - accuracy: 0.7366 - val_loss: 2.0288 - val_accuracy: 0.4703 - lr: 0.0037\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.3794 - accuracy: 0.7470 - val_loss: 2.2144 - val_accuracy: 0.4333 - lr: 0.0037\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.3371 - accuracy: 0.7670 - val_loss: 1.9550 - val_accuracy: 0.4647 - lr: 0.0037\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.2313 - accuracy: 0.8042 - val_loss: 0.6815 - val_accuracy: 0.8533 - lr: 3.7318e-04\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.1860 - accuracy: 0.8199 - val_loss: 0.4777 - val_accuracy: 0.9230 - lr: 3.7318e-04\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.1707 - accuracy: 0.8285 - val_loss: 0.5495 - val_accuracy: 0.9023 - lr: 3.7318e-04\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.1489 - accuracy: 0.8265 - val_loss: 0.4685 - val_accuracy: 0.9240 - lr: 3.7318e-04\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.1518 - accuracy: 0.8326 - val_loss: 0.4381 - val_accuracy: 0.9340 - lr: 3.7318e-04\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.1391 - accuracy: 0.8313 - val_loss: 0.4915 - val_accuracy: 0.9120 - lr: 3.7318e-04\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.1284 - accuracy: 0.8305 - val_loss: 0.4755 - val_accuracy: 0.9213 - lr: 3.7318e-04\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.1156 - accuracy: 0.8362 - val_loss: 0.5055 - val_accuracy: 0.9053 - lr: 3.7318e-04\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.1220 - accuracy: 0.8343 - val_loss: 0.4411 - val_accuracy: 0.9320 - lr: 3.7318e-04\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.1000 - accuracy: 0.8388 - val_loss: 0.7124 - val_accuracy: 0.8340 - lr: 3.7318e-04\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0917 - accuracy: 0.8428 - val_loss: 0.3516 - val_accuracy: 0.9587 - lr: 3.7318e-05\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0941 - accuracy: 0.8442 - val_loss: 0.3405 - val_accuracy: 0.9580 - lr: 3.7318e-05\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0838 - accuracy: 0.8438 - val_loss: 0.3375 - val_accuracy: 0.9587 - lr: 3.7318e-05\n",
      "Epoch 34/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0792 - accuracy: 0.8493 - val_loss: 0.3333 - val_accuracy: 0.9593 - lr: 3.7318e-05\n",
      "Epoch 35/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0811 - accuracy: 0.8429 - val_loss: 0.3339 - val_accuracy: 0.9580 - lr: 3.7318e-05\n",
      "Epoch 36/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0880 - accuracy: 0.8482 - val_loss: 0.3329 - val_accuracy: 0.9587 - lr: 3.7318e-05\n",
      "Epoch 37/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0746 - accuracy: 0.8487 - val_loss: 0.3278 - val_accuracy: 0.9603 - lr: 3.7318e-05\n",
      "Epoch 38/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0815 - accuracy: 0.8507 - val_loss: 0.3306 - val_accuracy: 0.9593 - lr: 3.7318e-05\n",
      "Epoch 39/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0701 - accuracy: 0.8478 - val_loss: 0.3262 - val_accuracy: 0.9610 - lr: 3.7318e-05\n",
      "Epoch 40/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0755 - accuracy: 0.8488 - val_loss: 0.3302 - val_accuracy: 0.9613 - lr: 3.7318e-05\n",
      "Epoch 41/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0775 - accuracy: 0.8422 - val_loss: 0.3255 - val_accuracy: 0.9603 - lr: 3.7318e-05\n",
      "Epoch 42/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0686 - accuracy: 0.8475 - val_loss: 0.3315 - val_accuracy: 0.9593 - lr: 3.7318e-05\n",
      "Epoch 43/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0664 - accuracy: 0.8482 - val_loss: 0.3268 - val_accuracy: 0.9600 - lr: 3.7318e-05\n",
      "Epoch 44/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0631 - accuracy: 0.8498 - val_loss: 0.3252 - val_accuracy: 0.9607 - lr: 3.7318e-05\n",
      "Epoch 45/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0636 - accuracy: 0.8582 - val_loss: 0.3212 - val_accuracy: 0.9620 - lr: 3.7318e-05\n",
      "Epoch 46/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0619 - accuracy: 0.8417 - val_loss: 0.3429 - val_accuracy: 0.9567 - lr: 3.7318e-05\n",
      "Epoch 47/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0618 - accuracy: 0.8460 - val_loss: 0.3264 - val_accuracy: 0.9617 - lr: 3.7318e-05\n",
      "Epoch 48/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0636 - accuracy: 0.8532 - val_loss: 0.3212 - val_accuracy: 0.9603 - lr: 3.7318e-05\n",
      "Epoch 49/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0672 - accuracy: 0.8479 - val_loss: 0.3233 - val_accuracy: 0.9623 - lr: 3.7318e-05\n",
      "Epoch 50/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0657 - accuracy: 0.8449 - val_loss: 0.3259 - val_accuracy: 0.9603 - lr: 3.7318e-05\n",
      "Epoch 51/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0616 - accuracy: 0.8554 - val_loss: 0.3198 - val_accuracy: 0.9617 - lr: 3.7318e-06\n",
      "Epoch 52/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0592 - accuracy: 0.8520 - val_loss: 0.3191 - val_accuracy: 0.9627 - lr: 3.7318e-06\n",
      "Epoch 53/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0637 - accuracy: 0.8504 - val_loss: 0.3195 - val_accuracy: 0.9630 - lr: 3.7318e-06\n",
      "Epoch 54/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0631 - accuracy: 0.8523 - val_loss: 0.3192 - val_accuracy: 0.9620 - lr: 3.7318e-06\n",
      "Epoch 55/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0618 - accuracy: 0.8529 - val_loss: 0.3190 - val_accuracy: 0.9620 - lr: 3.7318e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0a4bfe22b0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.fit(train_ds_cutmix, epochs=100, validation_data=val_ds_cutmix ,  callbacks = [EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True), ReduceLROnPlateau(patience=5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1\"></a>\n",
    "## <font color='#71a1e3'> __With Auto Encoder__</font>\n",
    "<hr style=\"height:1.5px;border-width:0;background-color: #4c8c77\">\n",
    "\n",
    "Here we will do the the model on the dataset where their is removal of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Analysis to see if it improve models\n",
    "\n",
    "- Auto Encoder are a type of deep-learning architectures that are used to learn how to compress and decompress data faithfully.\n",
    "- The compression layers are referred to as the encoding layers, and the decompression layers are referred to as the decoding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN2(name='CNN2_Final'):\n",
    "\n",
    "    filters_list = [128, 128, 128]\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add initial convolutional layers\n",
    "    model.add(Conv2D(filters=filters_list[0], kernel_size=(3, 3), padding='same', input_shape=(31, 31, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(Conv2D(filters=filters_list[1], kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    for filters in filters_list:\n",
    "        model.add(Conv2D(filters=filters, kernel_size=(3, 3), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(15, activation='softmax')) \n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9028, 31, 31, 1), dtype=float32, numpy=\n",
       "array([[[[172.45367  ],\n",
       "         [172.42911  ],\n",
       "         [148.3763   ],\n",
       "         ...,\n",
       "         [  9.082149 ],\n",
       "         [ 74.1846   ],\n",
       "         [ 75.39283  ]],\n",
       "\n",
       "        [[162.70618  ],\n",
       "         [135.46048  ],\n",
       "         [138.79718  ],\n",
       "         ...,\n",
       "         [  8.52884  ],\n",
       "         [107.87208  ],\n",
       "         [ 28.14853  ]],\n",
       "\n",
       "        [[167.73225  ],\n",
       "         [155.02101  ],\n",
       "         [160.99945  ],\n",
       "         ...,\n",
       "         [ 50.25738  ],\n",
       "         [ 68.86168  ],\n",
       "         [ 50.25877  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 14.9373   ],\n",
       "         [  0.632849 ],\n",
       "         [  4.264825 ],\n",
       "         ...,\n",
       "         [  0.6839429],\n",
       "         [  3.0468068],\n",
       "         [  5.292361 ]],\n",
       "\n",
       "        [[  0.5858328],\n",
       "         [  5.728203 ],\n",
       "         [  8.312161 ],\n",
       "         ...,\n",
       "         [  7.5142198],\n",
       "         [  5.191881 ],\n",
       "         [  7.5142198]],\n",
       "\n",
       "        [[ 15.314268 ],\n",
       "         [ 18.25876  ],\n",
       "         [ 15.064908 ],\n",
       "         ...,\n",
       "         [  9.060153 ],\n",
       "         [  8.925923 ],\n",
       "         [ 10.138852 ]]],\n",
       "\n",
       "\n",
       "       [[[193.64117  ],\n",
       "         [194.83122  ],\n",
       "         [195.23166  ],\n",
       "         ...,\n",
       "         [175.90071  ],\n",
       "         [176.9006   ],\n",
       "         [176.0136   ]],\n",
       "\n",
       "        [[193.1701   ],\n",
       "         [195.1098   ],\n",
       "         [196.03882  ],\n",
       "         ...,\n",
       "         [175.90071  ],\n",
       "         [176.23938  ],\n",
       "         [176.9006   ]],\n",
       "\n",
       "        [[192.99489  ],\n",
       "         [194.22058  ],\n",
       "         [196.91     ],\n",
       "         ...,\n",
       "         [175.6727   ],\n",
       "         [176.9006   ],\n",
       "         [176.9006   ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[174.6944   ],\n",
       "         [173.6945   ],\n",
       "         [172.69461  ],\n",
       "         ...,\n",
       "         [172.5798   ],\n",
       "         [172.8256   ],\n",
       "         [173.82552  ]],\n",
       "\n",
       "        [[172.03915  ],\n",
       "         [171.09358  ],\n",
       "         [170.39258  ],\n",
       "         ...,\n",
       "         [170.45251  ],\n",
       "         [172.04967  ],\n",
       "         [172.83519  ]],\n",
       "\n",
       "        [[168.83559  ],\n",
       "         [167.31717  ],\n",
       "         [165.36848  ],\n",
       "         ...,\n",
       "         [166.8251   ],\n",
       "         [170.2422   ],\n",
       "         [171.98264  ]]],\n",
       "\n",
       "\n",
       "       [[[ 82.512    ],\n",
       "         [139.06451  ],\n",
       "         [145.55531  ],\n",
       "         ...,\n",
       "         [ 58.364292 ],\n",
       "         [ 31.03733  ],\n",
       "         [ 41.66342  ]],\n",
       "\n",
       "        [[126.93477  ],\n",
       "         [121.61825  ],\n",
       "         [127.76819  ],\n",
       "         ...,\n",
       "         [ 52.214436 ],\n",
       "         [ 47.239395 ],\n",
       "         [ 27.660324 ]],\n",
       "\n",
       "        [[176.44514  ],\n",
       "         [129.6598   ],\n",
       "         [131.62105  ],\n",
       "         ...,\n",
       "         [ 29.972208 ],\n",
       "         [ 41.01846  ],\n",
       "         [ 36.94515  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[147.9772   ],\n",
       "         [168.05223  ],\n",
       "         [157.06805  ],\n",
       "         ...,\n",
       "         [ 56.877274 ],\n",
       "         [ 48.841156 ],\n",
       "         [ 58.548965 ]],\n",
       "\n",
       "        [[ 25.51569  ],\n",
       "         [104.566734 ],\n",
       "         [ 99.39137  ],\n",
       "         ...,\n",
       "         [ 57.194595 ],\n",
       "         [ 65.10707  ],\n",
       "         [ 60.046555 ]],\n",
       "\n",
       "        [[ 79.3434   ],\n",
       "         [146.59338  ],\n",
       "         [101.88307  ],\n",
       "         ...,\n",
       "         [ 62.752647 ],\n",
       "         [ 75.40811  ],\n",
       "         [ 79.09191  ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[  7.7312503],\n",
       "         [  5.7485323],\n",
       "         [ 32.666515 ],\n",
       "         ...,\n",
       "         [168.91891  ],\n",
       "         [154.27328  ],\n",
       "         [139.45831  ]],\n",
       "\n",
       "        [[ 82.06943  ],\n",
       "         [ 70.16652  ],\n",
       "         [ 40.071583 ],\n",
       "         ...,\n",
       "         [176.99704  ],\n",
       "         [176.76967  ],\n",
       "         [171.03711  ]],\n",
       "\n",
       "        [[ 50.487144 ],\n",
       "         [ 62.904877 ],\n",
       "         [ 70.73659  ],\n",
       "         ...,\n",
       "         [190.80946  ],\n",
       "         [186.50252  ],\n",
       "         [156.31047  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 23.133339 ],\n",
       "         [ 21.542278 ],\n",
       "         [ 19.625145 ],\n",
       "         ...,\n",
       "         [113.86776  ],\n",
       "         [113.55285  ],\n",
       "         [120.425255 ]],\n",
       "\n",
       "        [[ 33.14797  ],\n",
       "         [ 26.812588 ],\n",
       "         [ 93.866    ],\n",
       "         ...,\n",
       "         [109.111084 ],\n",
       "         [117.65326  ],\n",
       "         [169.90996  ]],\n",
       "\n",
       "        [[ 61.134888 ],\n",
       "         [126.16603  ],\n",
       "         [ 42.15338  ],\n",
       "         ...,\n",
       "         [ 73.88635  ],\n",
       "         [ 74.85272  ],\n",
       "         [189.54161  ]]],\n",
       "\n",
       "\n",
       "       [[[ 40.74086  ],\n",
       "         [ 40.23635  ],\n",
       "         [ 79.64445  ],\n",
       "         ...,\n",
       "         [176.88716  ],\n",
       "         [160.75258  ],\n",
       "         [108.47284  ]],\n",
       "\n",
       "        [[ 35.81137  ],\n",
       "         [105.29154  ],\n",
       "         [ 77.64415  ],\n",
       "         ...,\n",
       "         [176.12741  ],\n",
       "         [182.1279   ],\n",
       "         [103.53454  ]],\n",
       "\n",
       "        [[ 47.41871  ],\n",
       "         [ 44.114326 ],\n",
       "         [ 71.69076  ],\n",
       "         ...,\n",
       "         [183.45988  ],\n",
       "         [182.47992  ],\n",
       "         [128.49803  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[126.01822  ],\n",
       "         [110.4254   ],\n",
       "         [138.96176  ],\n",
       "         ...,\n",
       "         [ 77.224304 ],\n",
       "         [ 60.163605 ],\n",
       "         [ 71.154205 ]],\n",
       "\n",
       "        [[149.29305  ],\n",
       "         [112.26802  ],\n",
       "         [173.1265   ],\n",
       "         ...,\n",
       "         [ 70.999306 ],\n",
       "         [ 23.4831   ],\n",
       "         [ 75.09721  ]],\n",
       "\n",
       "        [[166.74539  ],\n",
       "         [164.93007  ],\n",
       "         [161.25201  ],\n",
       "         ...,\n",
       "         [ 67.40949  ],\n",
       "         [ 26.896173 ],\n",
       "         [ 71.39684  ]]],\n",
       "\n",
       "\n",
       "       [[[156.91318  ],\n",
       "         [142.01895  ],\n",
       "         [119.60278  ],\n",
       "         ...,\n",
       "         [146.70384  ],\n",
       "         [139.98125  ],\n",
       "         [120.82509  ]],\n",
       "\n",
       "        [[116.40975  ],\n",
       "         [123.081154 ],\n",
       "         [ 99.687546 ],\n",
       "         ...,\n",
       "         [146.57274  ],\n",
       "         [ 90.74941  ],\n",
       "         [121.43551  ]],\n",
       "\n",
       "        [[132.07002  ],\n",
       "         [111.73427  ],\n",
       "         [105.86336  ],\n",
       "         ...,\n",
       "         [120.34705  ],\n",
       "         [139.17651  ],\n",
       "         [128.70073  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 74.77275  ],\n",
       "         [ 89.17192  ],\n",
       "         [ 83.552475 ],\n",
       "         ...,\n",
       "         [ 68.47485  ],\n",
       "         [ 59.893208 ],\n",
       "         [ 44.92494  ]],\n",
       "\n",
       "        [[ 77.77922  ],\n",
       "         [ 77.80911  ],\n",
       "         [ 79.87411  ],\n",
       "         ...,\n",
       "         [ 70.476585 ],\n",
       "         [ 51.820377 ],\n",
       "         [ 46.45889  ]],\n",
       "\n",
       "        [[ 80.61083  ],\n",
       "         [ 87.11542  ],\n",
       "         [ 90.32149  ],\n",
       "         ...,\n",
       "         [ 46.07469  ],\n",
       "         [ 69.37136  ],\n",
       "         [ 49.135406 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(X_train_small, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: -1487.5659 - val_loss: -1737.6346\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.2012 - val_loss: -1737.9570\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.4813 - val_loss: -1738.1696\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.5875 - val_loss: -1738.2070\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6113 - val_loss: -1738.2194\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6211 - val_loss: -1738.2252\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6262 - val_loss: -1738.2288\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6290 - val_loss: -1738.2311\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6315 - val_loss: -1738.2327\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6345 - val_loss: -1738.2355\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6368 - val_loss: -1738.2366\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6382 - val_loss: -1738.2368\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6381 - val_loss: -1738.2372\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6383 - val_loss: -1738.2372\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6382 - val_loss: -1738.2373\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2373\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6379 - val_loss: -1738.2373\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2373\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2373\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6383 - val_loss: -1738.2373\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6383 - val_loss: -1738.2373\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6383 - val_loss: -1738.2373\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6382 - val_loss: -1738.2373\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2373\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6382 - val_loss: -1738.2373\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2373\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2373\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6382 - val_loss: -1738.2373\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2373\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2373\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2373\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6382 - val_loss: -1738.2373\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2374\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6382 - val_loss: -1738.2374\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6388 - val_loss: -1738.2374\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2374\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2374\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6388 - val_loss: -1738.2374\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2374\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6388 - val_loss: -1738.2374\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6383 - val_loss: -1738.2374\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6382 - val_loss: -1738.2374\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2374\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6383 - val_loss: -1738.2374\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2374\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2374\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2374\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2374\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2374\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2374\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2374\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6383 - val_loss: -1738.2374\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2374\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6383 - val_loss: -1738.2374\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2374\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6388 - val_loss: -1738.2374\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2374\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2374\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2374\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2374\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6388 - val_loss: -1738.2374\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6390 - val_loss: -1738.2374\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2374\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2374\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2374\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2374\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2374\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2374\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2374\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6389 - val_loss: -1738.2374\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6383 - val_loss: -1738.2374\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6382 - val_loss: -1738.2374\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2374\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2374\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6383 - val_loss: -1738.2374\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6383 - val_loss: -1738.2374\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6387 - val_loss: -1738.2374\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6385 - val_loss: -1738.2374\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6384 - val_loss: -1738.2374\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6383 - val_loss: -1738.2374\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: -1727.6388 - val_loss: -1738.2374\n"
     ]
    }
   ],
   "source": [
    "X_train_small_expanded = tf.expand_dims(X_train_small, -1)\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, InputLayer, Cropping2D\n",
    "# Encoder\n",
    "encoder = Sequential([\n",
    "    InputLayer(input_shape=X_train_small_expanded.shape[1:]),\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),\n",
    "    Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)\n",
    "])\n",
    "\n",
    "# Decoder\n",
    "decoder = Sequential([\n",
    "    Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "    Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "    Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same'),\n",
    "    Cropping2D(cropping=((1, 0), (1, 0))) \n",
    "])\n",
    "\n",
    "autoencoder = Sequential([encoder, decoder])\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "history = autoencoder.fit(\n",
    "    X_train_small_expanded, X_train_small_expanded,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([15019.677, 26186.443, 13155.19 , ..., 21750.482, 14109.178,\n",
       "       12477.434], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed = autoencoder.predict(X_train_small)\n",
    "reconstruction_error = np.mean(np.power( tf.expand_dims(X_train_small, -1) - reconstructed, 2), axis=(1,2,3))\n",
    "reconstruction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.quantile(reconstruction_error, 0.99)  \n",
    "outliers = X_train_small[reconstruction_error > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x800 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10 \n",
    "plt.figure(figsize=(20, 8))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.imshow(outliers[i]) \n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_title(f'Outlier {i+1}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.quantile(reconstruction_error, 0.99)  \n",
    "non_outliers = X_train_small[reconstruction_error <= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_outliers_labels = y_train_small[reconstruction_error <= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 31, 31, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 15), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_one = tf.data.Dataset.from_tensor_slices((non_outliers, non_outliers_labels)).shuffle(2048).map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds_two = tf.data.Dataset.from_tensor_slices((non_outliers, non_outliers_labels)).shuffle(2048).map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds_cutmix = tf.data.Dataset.from_tensor_slices((X_val_small, y_val_small))\n",
    "val_ds_cutmix = val_ds_cutmix.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE).batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds_cutmix = tf.data.Dataset.zip((train_ds_one, train_ds_two))\n",
    "train_ds_cutmix = (\n",
    "    train_ds_cutmix.shuffle(1024)\n",
    "    .map(cutmix, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(128)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "train_ds_cutmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0547 - accuracy: 0.8590 - val_loss: 0.3061 - val_accuracy: 0.9667 - lr: 3.7318e-05\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0507 - accuracy: 0.8541 - val_loss: 0.2963 - val_accuracy: 0.9680 - lr: 3.7318e-05\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0342 - accuracy: 0.8611 - val_loss: 0.3121 - val_accuracy: 0.9610 - lr: 3.7318e-05\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0428 - accuracy: 0.8629 - val_loss: 0.2930 - val_accuracy: 0.9693 - lr: 3.7318e-05\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0416 - accuracy: 0.8601 - val_loss: 0.2990 - val_accuracy: 0.9653 - lr: 3.7318e-05\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0439 - accuracy: 0.8588 - val_loss: 0.3025 - val_accuracy: 0.9660 - lr: 3.7318e-05\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0409 - accuracy: 0.8512 - val_loss: 0.3016 - val_accuracy: 0.9643 - lr: 3.7318e-05\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0360 - accuracy: 0.8560 - val_loss: 0.2950 - val_accuracy: 0.9667 - lr: 3.7318e-05\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0446 - accuracy: 0.8551 - val_loss: 0.3014 - val_accuracy: 0.9650 - lr: 3.7318e-05\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0353 - accuracy: 0.8552 - val_loss: 0.2944 - val_accuracy: 0.9680 - lr: 3.7318e-06\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0368 - accuracy: 0.8600 - val_loss: 0.2938 - val_accuracy: 0.9667 - lr: 3.7318e-06\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0369 - accuracy: 0.8592 - val_loss: 0.2934 - val_accuracy: 0.9667 - lr: 3.7318e-06\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0360 - accuracy: 0.8581 - val_loss: 0.2918 - val_accuracy: 0.9677 - lr: 3.7318e-06\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 1s 17ms/step - loss: 1.0367 - accuracy: 0.8570 - val_loss: 0.2923 - val_accuracy: 0.9677 - lr: 3.7318e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0a53537f70>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(train_ds_cutmix,validation_data = val_ds_cutmix, epochs=100, batch_size=64,  callbacks=[EarlyStopping(monitor='accuracy', patience=10, restore_best_weights=True), ReduceLROnPlateau(patience=5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style=\"background-color:#a7c6d6; padding: 10px; border: 3px solid lightblue; border-radius: 5px; color:black\">\n",
    "<u><b><i>Things Observed</i></b></u>\n",
    "<ul>\n",
    "Overall, auto encoder did not really improve the model\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
